stages:
  - build
  - test
  - deploy

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  PRE_COMMIT_HOME: "$CI_PROJECT_DIR/.cache/pre-commit"

cache: &global-cache
  key:
    files:
      - poetry.lock
    prefix: $CI_JOB_NAME
  paths:
    - .cache
    - .venv
    - .tox
    - .poetry
  policy: pull-push

.prepare-env-template: &prepare-env
  before_script:
    # install tusd
    - wget https://github.com/tus/tusd/releases/download/v1.6.0/tusd_linux_amd64.tar.gz
    - tar xf tusd_linux_amd64.tar.gz
    - mv tusd_linux_amd64/tusd /usr/bin
    # install Python poetry
    - curl https://bootstrap.pypa.io/get-pip.py | python3
    - curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python3
    - source $HOME/.poetry/env
    - poetry --version
    # install project deps
    - poetry config virtualenvs.in-project true
    - poetry install -vv

# Generate documentation and expose as Gitlab job artifact, so that it can be downloaded.
make-docs:
  image: python:latest
  stage: deploy
  <<: *prepare-env
  script:
    - poetry run pdoc -o docs metador
    - pip install anybadge
    - anybadge -l download -v docs > docs-badge.svg
  artifacts:
    paths:
      - docs/
      - docs-badge.svg

# Run pre-commit, just to make sure the developers did not mess up.
run-pre-commit:
  image: python:latest
  stage: test
  variables:
  cache:
    key:
      files:
        - .pre-commit-config.yaml
      prefix: $CI_JOB_NAME
    paths:
      - .cache
  script:
    - pip install pre-commit
    - pre-commit run --all-files

# Run the tests with multiple Python interpreters with tox.
# run-pytest-tox:
#   image: fkrull/multi-python:latest
#   stage: test
#   <<: *prepare-env
#   script:
#     - poetry run tox

# Instead of using tox we can also run with multiple containers,
# based on the same job template.

# Job template. Just add an image with specific Python interpreter for an instance.
.run-pytest-template: &run-pytest
  stage: test
  <<: *prepare-env
  script:
    - poetry run pytest --cov=metador tests/ --junitxml=report.xml
  # for Gitlab integration of test results
  artifacts:
    when: always
    reports:
      junit: report.xml

# Base test job, defines cache that is shared among the others.
run-pytest-3.7:
  image: python:3.7
  <<: *run-pytest

run-pytest-3.8:
  image: python:3.8
  <<: *run-pytest

run-pytest-3.9:
  image: python:3.9
  <<: *run-pytest
